{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PKU-人工智能实践课-第一课-莺尾花代码\n",
    "\n",
    "Created by Henry Huang\n",
    "----\n",
    "代码实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.使用莺尾花数据集，进行神经网络初识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch=1000\n",
    "lr=0.05\n",
    "train_loss_result=[]\n",
    "test_acc=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据集\n",
    "\n",
    "（遇到错误ImportError: cannot import name 'datasets'）--似乎是没有安装sklearn导致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = datasets.load_iris().data #返回iris数据集所有输入特征\n",
    "y_data = datasets.load_iris().target #返回iris数据集所有标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据进行乱序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(115) # 使用相同的seed，使输入特征/标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(115)\n",
    "np.random.shuffle(y_data) \n",
    "tf.random.set_seed(115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分开训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "知识点就是<font color=red>Python的正负索引</font>\n",
    "\n",
    "列表中每个数都有一个正索引和负的索引。\n",
    "\n",
    "切片时候，step为正决定从左往右取数，step为负决定从右往左取数。\n",
    "\n",
    "**正索引：**左边第一个数索引是0，然后从左开始递增。\n",
    "\n",
    "**负索引:**右边第一个数索引是0，然后从右边开始递减。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_data[:-30]#这个操作结果跟[0:150-30]的效果是一样的\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后分batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "#train_db=tf.cast(train_db,dtype=tf.double)\n",
    "#test_db=tf.cast(test_db,dtype=tf.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个4*3的全连接网络\n",
    "\n",
    "<font color=red>这里必须将所有的都转化为float32才能进行矩阵乘法运算。float64不行，难道是怕乘法溢出？</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random.truncated_normal([4,3], stddev=0.1, seed=2))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=2))\n",
    "w1=tf.cast(w1,dtype=tf.float32)\n",
    "b1=tf.cast(b1,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.0602487176656723\n",
      "test_acc: 0.43333333333333335\n",
      "Epoch 1, loss: 0.05828311666846275\n",
      "test_acc: 0.0\n",
      "Epoch 2, loss: 0.05677108094096184\n",
      "test_acc: 0.03333333333333333\n",
      "Epoch 3, loss: 0.05519834905862808\n",
      "test_acc: 0.0\n",
      "Epoch 4, loss: 0.05358148366212845\n",
      "test_acc: 0.23333333333333334\n",
      "Epoch 5, loss: 0.05196031555533409\n",
      "test_acc: 0.5666666666666667\n",
      "Epoch 6, loss: 0.05036843940615654\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 7, loss: 0.048831336200237274\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 8, loss: 0.047367095947265625\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 9, loss: 0.04598727077245712\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 10, loss: 0.04469788819551468\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 11, loss: 0.04350047558546066\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 12, loss: 0.04239322617650032\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 13, loss: 0.04137204959988594\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 14, loss: 0.040431465953588486\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 15, loss: 0.03956528380513191\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 16, loss: 0.03876712545752525\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 17, loss: 0.0380307175219059\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 18, loss: 0.03735010325908661\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 19, loss: 0.03671976923942566\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 20, loss: 0.03613466024398804\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 21, loss: 0.03559021279215813\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 22, loss: 0.03508232533931732\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 23, loss: 0.03460734710097313\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 24, loss: 0.0341620035469532\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 25, loss: 0.03374340012669563\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 26, loss: 0.03334895893931389\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 27, loss: 0.03297638148069382\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 28, loss: 0.032623641192913055\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 29, loss: 0.03228892385959625\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 30, loss: 0.03197062015533447\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 31, loss: 0.03166728466749191\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 32, loss: 0.0313776358962059\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 33, loss: 0.031100532039999962\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 34, loss: 0.03083493374288082\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 35, loss: 0.030579915270209312\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 36, loss: 0.030334651470184326\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 37, loss: 0.030098391696810722\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 38, loss: 0.02987046353518963\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 39, loss: 0.0296502485871315\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 40, loss: 0.029437197372317314\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 41, loss: 0.029230812564492226\n",
      "test_acc: 0.6333333333333333\n",
      "Epoch 42, loss: 0.029030630365014076\n",
      "test_acc: 0.6666666666666666\n",
      "Epoch 43, loss: 0.028836242854595184\n",
      "test_acc: 0.7\n",
      "Epoch 44, loss: 0.02864726446568966\n",
      "test_acc: 0.7\n",
      "Epoch 45, loss: 0.02846335619688034\n",
      "test_acc: 0.7\n",
      "Epoch 46, loss: 0.02828419953584671\n",
      "test_acc: 0.7666666666666667\n",
      "Epoch 47, loss: 0.028109503909945488\n",
      "test_acc: 0.7666666666666667\n",
      "Epoch 48, loss: 0.027939001098275185\n",
      "test_acc: 0.7666666666666667\n",
      "Epoch 49, loss: 0.027772454544901848\n",
      "test_acc: 0.7666666666666667\n",
      "Epoch 50, loss: 0.02760963700711727\n",
      "test_acc: 0.7666666666666667\n",
      "Epoch 51, loss: 0.02745033986866474\n",
      "test_acc: 0.7666666666666667\n",
      "Epoch 52, loss: 0.027294375002384186\n",
      "test_acc: 0.8\n",
      "Epoch 53, loss: 0.02714156173169613\n",
      "test_acc: 0.8\n",
      "Epoch 54, loss: 0.026991745457053185\n",
      "test_acc: 0.8\n",
      "Epoch 55, loss: 0.02684476226568222\n",
      "test_acc: 0.8333333333333334\n",
      "Epoch 56, loss: 0.026700489223003387\n",
      "test_acc: 0.8666666666666667\n",
      "Epoch 57, loss: 0.026558782905340195\n",
      "test_acc: 0.9\n",
      "Epoch 58, loss: 0.02641952969133854\n",
      "test_acc: 0.9\n",
      "Epoch 59, loss: 0.026282615959644318\n",
      "test_acc: 0.9\n",
      "Epoch 60, loss: 0.026147935539484024\n",
      "test_acc: 0.9\n",
      "Epoch 61, loss: 0.026015393435955048\n",
      "test_acc: 0.9\n",
      "Epoch 62, loss: 0.025884896516799927\n",
      "test_acc: 0.9\n",
      "Epoch 63, loss: 0.025756362825632095\n",
      "test_acc: 0.9\n",
      "Epoch 64, loss: 0.02562970668077469\n",
      "test_acc: 0.9\n",
      "Epoch 65, loss: 0.025504864752292633\n",
      "test_acc: 0.9\n",
      "Epoch 66, loss: 0.02538175694644451\n",
      "test_acc: 0.9\n",
      "Epoch 67, loss: 0.0252603217959404\n",
      "test_acc: 0.9\n",
      "Epoch 68, loss: 0.02514049783349037\n",
      "test_acc: 0.9\n",
      "Epoch 69, loss: 0.025022225454449654\n",
      "test_acc: 0.9\n",
      "Epoch 70, loss: 0.024905456230044365\n",
      "test_acc: 0.9\n",
      "Epoch 71, loss: 0.02479013241827488\n",
      "test_acc: 0.9\n",
      "Epoch 72, loss: 0.024676209315657616\n",
      "test_acc: 0.9\n",
      "Epoch 73, loss: 0.024563640356063843\n",
      "test_acc: 0.9\n",
      "Epoch 74, loss: 0.02445238269865513\n",
      "test_acc: 0.9\n",
      "Epoch 75, loss: 0.02434239722788334\n",
      "test_acc: 0.9\n",
      "Epoch 76, loss: 0.02423364669084549\n",
      "test_acc: 0.9\n",
      "Epoch 77, loss: 0.024126090109348297\n",
      "test_acc: 0.9\n",
      "Epoch 78, loss: 0.024019693955779076\n",
      "test_acc: 0.9\n",
      "Epoch 79, loss: 0.023914434015750885\n",
      "test_acc: 0.9\n",
      "Epoch 80, loss: 0.023810267448425293\n",
      "test_acc: 0.9\n",
      "Epoch 81, loss: 0.023707173764705658\n",
      "test_acc: 0.9\n",
      "Epoch 82, loss: 0.02360512502491474\n",
      "test_acc: 0.9\n",
      "Epoch 83, loss: 0.023504087701439857\n",
      "test_acc: 0.9\n",
      "Epoch 84, loss: 0.023404041305184364\n",
      "test_acc: 0.9\n",
      "Epoch 85, loss: 0.023304961621761322\n",
      "test_acc: 0.9\n",
      "Epoch 86, loss: 0.02320682629942894\n",
      "test_acc: 0.9\n",
      "Epoch 87, loss: 0.023109611123800278\n",
      "test_acc: 0.9333333333333333\n",
      "Epoch 88, loss: 0.023013301193714142\n",
      "test_acc: 0.9333333333333333\n",
      "Epoch 89, loss: 0.022917870432138443\n",
      "test_acc: 0.9333333333333333\n",
      "Epoch 90, loss: 0.02282330021262169\n",
      "test_acc: 0.9333333333333333\n",
      "Epoch 91, loss: 0.022729575634002686\n",
      "test_acc: 0.9333333333333333\n",
      "Epoch 92, loss: 0.02263668179512024\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 93, loss: 0.02254459261894226\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 94, loss: 0.022453300654888153\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 95, loss: 0.022362791001796722\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 96, loss: 0.022273041307926178\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 97, loss: 0.022184045985341072\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 98, loss: 0.022095786407589912\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 99, loss: 0.022008249536156654\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 100, loss: 0.021921426057815552\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 101, loss: 0.02183530293405056\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 102, loss: 0.021749867126345634\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 103, loss: 0.02166510559618473\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 104, loss: 0.02158101461827755\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 105, loss: 0.02149757742881775\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 106, loss: 0.02141478843986988\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 107, loss: 0.0213326308876276\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 108, loss: 0.021251104772090912\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 109, loss: 0.02117019332945347\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 110, loss: 0.021089890971779823\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 111, loss: 0.02101019024848938\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 112, loss: 0.020931081846356392\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 113, loss: 0.020852558314800262\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 114, loss: 0.020774610340595245\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 115, loss: 0.020697232335805893\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 116, loss: 0.02062041312456131\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 117, loss: 0.020544150844216347\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 118, loss: 0.020468436181545258\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 119, loss: 0.020393261685967445\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 120, loss: 0.020318619906902313\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 121, loss: 0.020244508981704712\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 122, loss: 0.020170919597148895\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 123, loss: 0.020097846165299416\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 124, loss: 0.020025283098220825\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 125, loss: 0.019953221082687378\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 126, loss: 0.019881658256053925\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 127, loss: 0.019810590893030167\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 128, loss: 0.01974000781774521\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 129, loss: 0.01966991275548935\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 130, loss: 0.019600290805101395\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 131, loss: 0.019531141966581345\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 132, loss: 0.01946246065199375\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 133, loss: 0.019394241273403168\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 134, loss: 0.019326481968164444\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 135, loss: 0.019259175285696983\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 136, loss: 0.019192315638065338\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 137, loss: 0.01912589929997921\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 138, loss: 0.01905992440879345\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 139, loss: 0.01899438351392746\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 140, loss: 0.01892927661538124\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 141, loss: 0.018864594399929047\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 142, loss: 0.018800338730216026\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 143, loss: 0.018736498430371284\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 144, loss: 0.01867307536303997\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 145, loss: 0.018610067665576935\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 146, loss: 0.018547462299466133\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 147, loss: 0.018485262989997864\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 148, loss: 0.01842346414923668\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 149, loss: 0.01836206391453743\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 150, loss: 0.01830105483531952\n",
      "test_acc: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151, loss: 0.018240435048937798\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 152, loss: 0.018180200830101967\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 153, loss: 0.018120352178812027\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 154, loss: 0.01806088350713253\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 155, loss: 0.01800178736448288\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 156, loss: 0.017943065613508224\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 157, loss: 0.017884714528918266\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 158, loss: 0.017826728522777557\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 159, loss: 0.017769111320376396\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 160, loss: 0.017711851745843887\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 161, loss: 0.01765494793653488\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 162, loss: 0.01759839989244938\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 163, loss: 0.01754220388829708\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 164, loss: 0.01748635619878769\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 165, loss: 0.017430854961276054\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 166, loss: 0.01737569272518158\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 167, loss: 0.017320873215794563\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 168, loss: 0.017266390845179558\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 169, loss: 0.017212241888046265\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 170, loss: 0.017158428207039833\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 171, loss: 0.017104940488934517\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 172, loss: 0.017051778733730316\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 173, loss: 0.01699894294142723\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 174, loss: 0.016946427524089813\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 175, loss: 0.016894232481718063\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 176, loss: 0.016842350363731384\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 177, loss: 0.016790784895420074\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 178, loss: 0.016739530488848686\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 179, loss: 0.016688581556081772\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 180, loss: 0.01663794182240963\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 181, loss: 0.016587605699896812\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 182, loss: 0.016537567600607872\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 183, loss: 0.016487833112478256\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 184, loss: 0.01643839105963707\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 185, loss: 0.01638924703001976\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 186, loss: 0.01634039543569088\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 187, loss: 0.01629183441400528\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 188, loss: 0.016243556514382362\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 189, loss: 0.016195565462112427\n",
      "test_acc: 0.9666666666666667\n",
      "Epoch 190, loss: 0.016147859394550323\n",
      "test_acc: 1.0\n",
      "Epoch 191, loss: 0.016100436449050903\n",
      "test_acc: 1.0\n",
      "Epoch 192, loss: 0.01605328917503357\n",
      "test_acc: 1.0\n",
      "Epoch 193, loss: 0.01600641757249832\n",
      "test_acc: 1.0\n",
      "Epoch 194, loss: 0.01595982536673546\n",
      "test_acc: 1.0\n",
      "Epoch 195, loss: 0.015913501381874084\n",
      "test_acc: 1.0\n",
      "Epoch 196, loss: 0.01586744748055935\n",
      "test_acc: 1.0\n",
      "Epoch 197, loss: 0.0158216655254364\n",
      "test_acc: 1.0\n",
      "Epoch 198, loss: 0.015776148065924644\n",
      "test_acc: 1.0\n",
      "Epoch 199, loss: 0.01573089510202408\n",
      "test_acc: 1.0\n",
      "Epoch 200, loss: 0.015685904771089554\n",
      "test_acc: 1.0\n",
      "Epoch 201, loss: 0.015641173347830772\n",
      "test_acc: 1.0\n",
      "Epoch 202, loss: 0.015596698969602585\n",
      "test_acc: 1.0\n",
      "Epoch 203, loss: 0.015552486293017864\n",
      "test_acc: 1.0\n",
      "Epoch 204, loss: 0.015508526004850864\n",
      "test_acc: 1.0\n",
      "Epoch 205, loss: 0.015464816242456436\n",
      "test_acc: 1.0\n",
      "Epoch 206, loss: 0.015421360731124878\n",
      "test_acc: 1.0\n",
      "Epoch 207, loss: 0.015378151088953018\n",
      "test_acc: 1.0\n",
      "Epoch 208, loss: 0.015335191041231155\n",
      "test_acc: 1.0\n",
      "Epoch 209, loss: 0.015292475931346416\n",
      "test_acc: 1.0\n",
      "Epoch 210, loss: 0.015250002034008503\n",
      "test_acc: 1.0\n",
      "Epoch 211, loss: 0.015207771211862564\n",
      "test_acc: 1.0\n",
      "Epoch 212, loss: 0.015165779739618301\n",
      "test_acc: 1.0\n",
      "Epoch 213, loss: 0.01512402668595314\n",
      "test_acc: 1.0\n",
      "Epoch 214, loss: 0.01508251205086708\n",
      "test_acc: 1.0\n",
      "Epoch 215, loss: 0.015041225589811802\n",
      "test_acc: 1.0\n",
      "Epoch 216, loss: 0.015000177547335625\n",
      "test_acc: 1.0\n",
      "Epoch 217, loss: 0.014959361404180527\n",
      "test_acc: 1.0\n",
      "Epoch 218, loss: 0.014918770641088486\n",
      "test_acc: 1.0\n",
      "Epoch 219, loss: 0.014878411777317524\n",
      "test_acc: 1.0\n",
      "Epoch 220, loss: 0.01483827456831932\n",
      "test_acc: 1.0\n",
      "Epoch 221, loss: 0.014798366464674473\n",
      "test_acc: 1.0\n",
      "Epoch 222, loss: 0.014758674427866936\n",
      "test_acc: 1.0\n",
      "Epoch 223, loss: 0.014719206839799881\n",
      "test_acc: 1.0\n",
      "Epoch 224, loss: 0.01467995997518301\n",
      "test_acc: 1.0\n",
      "Epoch 225, loss: 0.01464092917740345\n",
      "test_acc: 1.0\n",
      "Epoch 226, loss: 0.0146021181717515\n",
      "test_acc: 1.0\n",
      "Epoch 227, loss: 0.01456351950764656\n",
      "test_acc: 1.0\n",
      "Epoch 228, loss: 0.01452513225376606\n",
      "test_acc: 1.0\n",
      "Epoch 229, loss: 0.014486957341432571\n",
      "test_acc: 1.0\n",
      "Epoch 230, loss: 0.01444899570196867\n",
      "test_acc: 1.0\n",
      "Epoch 231, loss: 0.014411238953471184\n",
      "test_acc: 1.0\n",
      "Epoch 232, loss: 0.014373689889907837\n",
      "test_acc: 1.0\n",
      "Epoch 233, loss: 0.014336347579956055\n",
      "test_acc: 1.0\n",
      "Epoch 234, loss: 0.014299209229648113\n",
      "test_acc: 1.0\n",
      "Epoch 235, loss: 0.014262272045016289\n",
      "test_acc: 1.0\n",
      "Epoch 236, loss: 0.014225536026060581\n",
      "test_acc: 1.0\n",
      "Epoch 237, loss: 0.01418900303542614\n",
      "test_acc: 1.0\n",
      "Epoch 238, loss: 0.014152664691209793\n",
      "test_acc: 1.0\n",
      "Epoch 239, loss: 0.014116525650024414\n",
      "test_acc: 1.0\n",
      "Epoch 240, loss: 0.01408057939261198\n",
      "test_acc: 1.0\n",
      "Epoch 241, loss: 0.01404483150690794\n",
      "test_acc: 1.0\n",
      "Epoch 242, loss: 0.014009273611009121\n",
      "test_acc: 1.0\n",
      "Epoch 243, loss: 0.0139739029109478\n",
      "test_acc: 1.0\n",
      "Epoch 244, loss: 0.013938729651272297\n",
      "test_acc: 1.0\n",
      "Epoch 245, loss: 0.013903740793466568\n",
      "test_acc: 1.0\n",
      "Epoch 246, loss: 0.013868939131498337\n",
      "test_acc: 1.0\n",
      "Epoch 247, loss: 0.013834323734045029\n",
      "test_acc: 1.0\n",
      "Epoch 248, loss: 0.01379989180713892\n",
      "test_acc: 1.0\n",
      "Epoch 249, loss: 0.013765644282102585\n",
      "test_acc: 1.0\n",
      "Epoch 250, loss: 0.013731581158936024\n",
      "test_acc: 1.0\n",
      "Epoch 251, loss: 0.013697695918381214\n",
      "test_acc: 1.0\n",
      "Epoch 252, loss: 0.013663990423083305\n",
      "test_acc: 1.0\n",
      "Epoch 253, loss: 0.013630462810397148\n",
      "test_acc: 1.0\n",
      "Epoch 254, loss: 0.013597113080322742\n",
      "test_acc: 1.0\n",
      "Epoch 255, loss: 0.01356393564492464\n",
      "test_acc: 1.0\n",
      "Epoch 256, loss: 0.01353093609213829\n",
      "test_acc: 1.0\n",
      "Epoch 257, loss: 0.013498108834028244\n",
      "test_acc: 1.0\n",
      "Epoch 258, loss: 0.013465454801917076\n",
      "test_acc: 1.0\n",
      "Epoch 259, loss: 0.013432970270514488\n",
      "test_acc: 1.0\n",
      "Epoch 260, loss: 0.01340065523982048\n",
      "test_acc: 1.0\n",
      "Epoch 261, loss: 0.013368509709835052\n",
      "test_acc: 1.0\n",
      "Epoch 262, loss: 0.01333653088659048\n",
      "test_acc: 1.0\n",
      "Epoch 263, loss: 0.013304716907441616\n",
      "test_acc: 1.0\n",
      "Epoch 264, loss: 0.013273070566356182\n",
      "test_acc: 1.0\n",
      "Epoch 265, loss: 0.013241584412753582\n",
      "test_acc: 1.0\n",
      "Epoch 266, loss: 0.013210263103246689\n",
      "test_acc: 1.0\n",
      "Epoch 267, loss: 0.01317910198122263\n",
      "test_acc: 1.0\n",
      "Epoch 268, loss: 0.013148104771971703\n",
      "test_acc: 1.0\n",
      "Epoch 269, loss: 0.013117261230945587\n",
      "test_acc: 1.0\n",
      "Epoch 270, loss: 0.01308657880872488\n",
      "test_acc: 1.0\n",
      "Epoch 271, loss: 0.013056052848696709\n",
      "test_acc: 1.0\n",
      "Epoch 272, loss: 0.013025685213506222\n",
      "test_acc: 1.0\n",
      "Epoch 273, loss: 0.012995470315217972\n",
      "test_acc: 1.0\n",
      "Epoch 274, loss: 0.012965408153831959\n",
      "test_acc: 1.0\n",
      "Epoch 275, loss: 0.012935502454638481\n",
      "test_acc: 1.0\n",
      "Epoch 276, loss: 0.012905743904411793\n",
      "test_acc: 1.0\n",
      "Epoch 277, loss: 0.01287613995373249\n",
      "test_acc: 1.0\n",
      "Epoch 278, loss: 0.012846683152019978\n",
      "test_acc: 1.0\n",
      "Epoch 279, loss: 0.012817377224564552\n",
      "test_acc: 1.0\n",
      "Epoch 280, loss: 0.012788215652108192\n",
      "test_acc: 1.0\n",
      "Epoch 281, loss: 0.012759202159941196\n",
      "test_acc: 1.0\n",
      "Epoch 282, loss: 0.012730334885418415\n",
      "test_acc: 1.0\n",
      "Epoch 283, loss: 0.012701611965894699\n",
      "test_acc: 1.0\n",
      "Epoch 284, loss: 0.012673032470047474\n",
      "test_acc: 1.0\n",
      "Epoch 285, loss: 0.012644595466554165\n",
      "test_acc: 1.0\n",
      "Epoch 286, loss: 0.012616301886737347\n",
      "test_acc: 1.0\n",
      "Epoch 287, loss: 0.01258814800530672\n",
      "test_acc: 1.0\n",
      "Epoch 288, loss: 0.012560133822262287\n",
      "test_acc: 1.0\n",
      "Epoch 289, loss: 0.012532259337604046\n",
      "test_acc: 1.0\n",
      "Epoch 290, loss: 0.012504521757364273\n",
      "test_acc: 1.0\n",
      "Epoch 291, loss: 0.012476922012865543\n",
      "test_acc: 1.0\n",
      "Epoch 292, loss: 0.012449458241462708\n",
      "test_acc: 1.0\n",
      "Epoch 293, loss: 0.012422127649188042\n",
      "test_acc: 1.0\n",
      "Epoch 294, loss: 0.01239493116736412\n",
      "test_acc: 1.0\n",
      "Epoch 295, loss: 0.012367870658636093\n",
      "test_acc: 1.0\n",
      "Epoch 296, loss: 0.012340941466391087\n",
      "test_acc: 1.0\n",
      "Epoch 297, loss: 0.012314144521951675\n",
      "test_acc: 1.0\n",
      "Epoch 298, loss: 0.01228747796267271\n",
      "test_acc: 1.0\n",
      "Epoch 299, loss: 0.012260941788554192\n",
      "test_acc: 1.0\n",
      "Epoch 300, loss: 0.01223453413695097\n",
      "test_acc: 1.0\n",
      "Epoch 301, loss: 0.012208253145217896\n",
      "test_acc: 1.0\n",
      "Epoch 302, loss: 0.012182099744677544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 1.0\n",
      "Epoch 303, loss: 0.01215607300400734\n",
      "test_acc: 1.0\n",
      "Epoch 304, loss: 0.012130173854529858\n",
      "test_acc: 1.0\n",
      "Epoch 305, loss: 0.0121043985709548\n",
      "test_acc: 1.0\n",
      "Epoch 306, loss: 0.012078747153282166\n",
      "test_acc: 1.0\n",
      "Epoch 307, loss: 0.012053216807544231\n",
      "test_acc: 1.0\n",
      "Epoch 308, loss: 0.012027809396386147\n",
      "test_acc: 1.0\n",
      "Epoch 309, loss: 0.012002524919807911\n",
      "test_acc: 1.0\n",
      "Epoch 310, loss: 0.011977359652519226\n",
      "test_acc: 1.0\n",
      "Epoch 311, loss: 0.011952314525842667\n",
      "test_acc: 1.0\n",
      "Epoch 312, loss: 0.011927390471100807\n",
      "test_acc: 1.0\n",
      "Epoch 313, loss: 0.01190258376300335\n",
      "test_acc: 1.0\n",
      "Epoch 314, loss: 0.011877892538905144\n",
      "test_acc: 1.0\n",
      "Epoch 315, loss: 0.01185331866145134\n",
      "test_acc: 1.0\n",
      "Epoch 316, loss: 0.011828863993287086\n",
      "test_acc: 1.0\n",
      "Epoch 317, loss: 0.011804522015154362\n",
      "test_acc: 1.0\n",
      "Epoch 318, loss: 0.01178029552102089\n",
      "test_acc: 1.0\n",
      "Epoch 319, loss: 0.011756181716918945\n",
      "test_acc: 1.0\n",
      "Epoch 320, loss: 0.011732179671525955\n",
      "test_acc: 1.0\n",
      "Epoch 321, loss: 0.011708293110132217\n",
      "test_acc: 1.0\n",
      "Epoch 322, loss: 0.01168451365083456\n",
      "test_acc: 1.0\n",
      "Epoch 323, loss: 0.011660849675536156\n",
      "test_acc: 1.0\n",
      "Epoch 324, loss: 0.011637293733656406\n",
      "test_acc: 1.0\n",
      "Epoch 325, loss: 0.011613849550485611\n",
      "test_acc: 1.0\n",
      "Epoch 326, loss: 0.011590510606765747\n",
      "test_acc: 1.0\n",
      "Epoch 327, loss: 0.011567280627787113\n",
      "test_acc: 1.0\n",
      "Epoch 328, loss: 0.011544156819581985\n",
      "test_acc: 1.0\n",
      "Epoch 329, loss: 0.011521143838763237\n",
      "test_acc: 1.0\n",
      "Epoch 330, loss: 0.01149823423475027\n",
      "test_acc: 1.0\n",
      "Epoch 331, loss: 0.011475428938865662\n",
      "test_acc: 1.0\n",
      "Epoch 332, loss: 0.01145272795110941\n",
      "test_acc: 1.0\n",
      "Epoch 333, loss: 0.011430134996771812\n",
      "test_acc: 1.0\n",
      "Epoch 334, loss: 0.011407642625272274\n",
      "test_acc: 1.0\n",
      "Epoch 335, loss: 0.011385254561901093\n",
      "test_acc: 1.0\n",
      "Epoch 336, loss: 0.01136296521872282\n",
      "test_acc: 1.0\n",
      "Epoch 337, loss: 0.011340780183672905\n",
      "test_acc: 1.0\n",
      "Epoch 338, loss: 0.011318692937493324\n",
      "test_acc: 1.0\n",
      "Epoch 339, loss: 0.011296708136796951\n",
      "test_acc: 1.0\n",
      "Epoch 340, loss: 0.011274822056293488\n",
      "test_acc: 1.0\n",
      "Epoch 341, loss: 0.011253032833337784\n",
      "test_acc: 1.0\n",
      "Epoch 342, loss: 0.011231344193220139\n",
      "test_acc: 1.0\n",
      "Epoch 343, loss: 0.011209753341972828\n",
      "test_acc: 1.0\n",
      "Epoch 344, loss: 0.011188257485628128\n",
      "test_acc: 1.0\n",
      "Epoch 345, loss: 0.011166859418153763\n",
      "test_acc: 1.0\n",
      "Epoch 346, loss: 0.011145558208227158\n",
      "test_acc: 1.0\n",
      "Epoch 347, loss: 0.01112434919923544\n",
      "test_acc: 1.0\n",
      "Epoch 348, loss: 0.011103236116468906\n",
      "test_acc: 1.0\n",
      "Epoch 349, loss: 0.011082218028604984\n",
      "test_acc: 1.0\n",
      "Epoch 350, loss: 0.0110612902790308\n",
      "test_acc: 1.0\n",
      "Epoch 351, loss: 0.0110404584556818\n",
      "test_acc: 1.0\n",
      "Epoch 352, loss: 0.011019717901945114\n",
      "test_acc: 1.0\n",
      "Epoch 353, loss: 0.01099906675517559\n",
      "test_acc: 1.0\n",
      "Epoch 354, loss: 0.010978509671986103\n",
      "test_acc: 1.0\n",
      "Epoch 355, loss: 0.010958041995763779\n",
      "test_acc: 1.0\n",
      "Epoch 356, loss: 0.010937662795186043\n",
      "test_acc: 1.0\n",
      "Epoch 357, loss: 0.01091737486422062\n",
      "test_acc: 1.0\n",
      "Epoch 358, loss: 0.010897175408899784\n",
      "test_acc: 1.0\n",
      "Epoch 359, loss: 0.010877061635255814\n",
      "test_acc: 1.0\n",
      "Epoch 360, loss: 0.010857039131224155\n",
      "test_acc: 1.0\n",
      "Epoch 361, loss: 0.010837102308869362\n",
      "test_acc: 1.0\n",
      "Epoch 362, loss: 0.010817253030836582\n",
      "test_acc: 1.0\n",
      "Epoch 363, loss: 0.010797489434480667\n",
      "test_acc: 1.0\n",
      "Epoch 364, loss: 0.010777810588479042\n",
      "test_acc: 1.0\n",
      "Epoch 365, loss: 0.010758217424154282\n",
      "test_acc: 1.0\n",
      "Epoch 366, loss: 0.01073871087282896\n",
      "test_acc: 1.0\n",
      "Epoch 367, loss: 0.01071928534656763\n",
      "test_acc: 1.0\n",
      "Epoch 368, loss: 0.010699942708015442\n",
      "test_acc: 1.0\n",
      "Epoch 369, loss: 0.010680686682462692\n",
      "test_acc: 1.0\n",
      "Epoch 370, loss: 0.01066150888800621\n",
      "test_acc: 1.0\n",
      "Epoch 371, loss: 0.010642417706549168\n",
      "test_acc: 1.0\n",
      "Epoch 372, loss: 0.010623406618833542\n",
      "test_acc: 1.0\n",
      "Epoch 373, loss: 0.010604476556181908\n",
      "test_acc: 1.0\n",
      "Epoch 374, loss: 0.010585624724626541\n",
      "test_acc: 1.0\n",
      "Epoch 375, loss: 0.01056685671210289\n",
      "test_acc: 1.0\n",
      "Epoch 376, loss: 0.010548165068030357\n",
      "test_acc: 1.0\n",
      "Epoch 377, loss: 0.010529554449021816\n",
      "test_acc: 1.0\n",
      "Epoch 378, loss: 0.010511022061109543\n",
      "test_acc: 1.0\n",
      "Epoch 379, loss: 0.010492567904293537\n",
      "test_acc: 1.0\n",
      "Epoch 380, loss: 0.01047419011592865\n",
      "test_acc: 1.0\n",
      "Epoch 381, loss: 0.01045589055866003\n",
      "test_acc: 1.0\n",
      "Epoch 382, loss: 0.010437666438519955\n",
      "test_acc: 1.0\n",
      "Epoch 383, loss: 0.010419522412121296\n",
      "test_acc: 1.0\n",
      "Epoch 384, loss: 0.010401451028883457\n",
      "test_acc: 1.0\n",
      "Epoch 385, loss: 0.010383456945419312\n",
      "test_acc: 1.0\n",
      "Epoch 386, loss: 0.010365535505115986\n",
      "test_acc: 1.0\n",
      "Epoch 387, loss: 0.010347690433263779\n",
      "test_acc: 1.0\n",
      "Epoch 388, loss: 0.010329920798540115\n",
      "test_acc: 1.0\n",
      "Epoch 389, loss: 0.010312220081686974\n",
      "test_acc: 1.0\n",
      "Epoch 390, loss: 0.010294594801962376\n",
      "test_acc: 1.0\n",
      "Epoch 391, loss: 0.010277044028043747\n",
      "test_acc: 1.0\n",
      "Epoch 392, loss: 0.010259564965963364\n",
      "test_acc: 1.0\n",
      "Epoch 393, loss: 0.010242156684398651\n",
      "test_acc: 1.0\n",
      "Epoch 394, loss: 0.010224821045994759\n",
      "test_acc: 1.0\n",
      "Epoch 395, loss: 0.010207555256783962\n",
      "test_acc: 1.0\n",
      "Epoch 396, loss: 0.010190360248088837\n",
      "test_acc: 1.0\n",
      "Epoch 397, loss: 0.010173236019909382\n",
      "test_acc: 1.0\n",
      "Epoch 398, loss: 0.010156182572245598\n",
      "test_acc: 1.0\n",
      "Epoch 399, loss: 0.010139198042452335\n",
      "test_acc: 1.0\n",
      "Epoch 400, loss: 0.010122284293174744\n",
      "test_acc: 1.0\n",
      "Epoch 401, loss: 0.0101054348051548\n",
      "test_acc: 1.0\n",
      "Epoch 402, loss: 0.010088654235005379\n",
      "test_acc: 1.0\n",
      "Epoch 403, loss: 0.010071942582726479\n",
      "test_acc: 1.0\n",
      "Epoch 404, loss: 0.010055300779640675\n",
      "test_acc: 1.0\n",
      "Epoch 405, loss: 0.010038722306489944\n",
      "test_acc: 1.0\n",
      "Epoch 406, loss: 0.010022214613854885\n",
      "test_acc: 1.0\n",
      "Epoch 407, loss: 0.010005771182477474\n",
      "test_acc: 1.0\n",
      "Epoch 408, loss: 0.009989392012357712\n",
      "test_acc: 1.0\n",
      "Epoch 409, loss: 0.009973078966140747\n",
      "test_acc: 1.0\n",
      "Epoch 410, loss: 0.009956832975149155\n",
      "test_acc: 1.0\n",
      "Epoch 411, loss: 0.009940650314092636\n",
      "test_acc: 1.0\n",
      "Epoch 412, loss: 0.00992453470826149\n",
      "test_acc: 1.0\n",
      "Epoch 413, loss: 0.009908478707075119\n",
      "test_acc: 1.0\n",
      "Epoch 414, loss: 0.009892488829791546\n",
      "test_acc: 1.0\n",
      "Epoch 415, loss: 0.009876562282443047\n",
      "test_acc: 1.0\n",
      "Epoch 416, loss: 0.009860698133707047\n",
      "test_acc: 1.0\n",
      "Epoch 417, loss: 0.009844895452260971\n",
      "test_acc: 1.0\n",
      "Epoch 418, loss: 0.009829159826040268\n",
      "test_acc: 1.0\n",
      "Epoch 419, loss: 0.009813481010496616\n",
      "test_acc: 1.0\n",
      "Epoch 420, loss: 0.009797867387533188\n",
      "test_acc: 1.0\n",
      "Epoch 421, loss: 0.009782311506569386\n",
      "test_acc: 1.0\n",
      "Epoch 422, loss: 0.009766818024218082\n",
      "test_acc: 1.0\n",
      "Epoch 423, loss: 0.00975138321518898\n",
      "test_acc: 1.0\n",
      "Epoch 424, loss: 0.009736010804772377\n",
      "test_acc: 1.0\n",
      "Epoch 425, loss: 0.009720697067677975\n",
      "test_acc: 1.0\n",
      "Epoch 426, loss: 0.009705445729196072\n",
      "test_acc: 1.0\n",
      "Epoch 427, loss: 0.009690250270068645\n",
      "test_acc: 1.0\n",
      "Epoch 428, loss: 0.00967511534690857\n",
      "test_acc: 1.0\n",
      "Epoch 429, loss: 0.009660039097070694\n",
      "test_acc: 1.0\n",
      "Epoch 430, loss: 0.00964501965790987\n",
      "test_acc: 1.0\n",
      "Epoch 431, loss: 0.009630061686038971\n",
      "test_acc: 1.0\n",
      "Epoch 432, loss: 0.009615156799554825\n",
      "test_acc: 1.0\n",
      "Epoch 433, loss: 0.00960030872374773\n",
      "test_acc: 1.0\n",
      "Epoch 434, loss: 0.009585520252585411\n",
      "test_acc: 1.0\n",
      "Epoch 435, loss: 0.009570787660777569\n",
      "test_acc: 1.0\n",
      "Epoch 436, loss: 0.009556110017001629\n",
      "test_acc: 1.0\n",
      "Epoch 437, loss: 0.009541491977870464\n",
      "test_acc: 1.0\n",
      "Epoch 438, loss: 0.009526927955448627\n",
      "test_acc: 1.0\n",
      "Epoch 439, loss: 0.009512417949736118\n",
      "test_acc: 1.0\n",
      "Epoch 440, loss: 0.009497963823378086\n",
      "test_acc: 1.0\n",
      "Epoch 441, loss: 0.009483564645051956\n",
      "test_acc: 1.0\n",
      "Epoch 442, loss: 0.00946921855211258\n",
      "test_acc: 1.0\n",
      "Epoch 443, loss: 0.00945492833852768\n",
      "test_acc: 1.0\n",
      "Epoch 444, loss: 0.009440691210329533\n",
      "test_acc: 1.0\n",
      "Epoch 445, loss: 0.009426506236195564\n",
      "test_acc: 1.0\n",
      "Epoch 446, loss: 0.009412377141416073\n",
      "test_acc: 1.0\n",
      "Epoch 447, loss: 0.009398301132023335\n",
      "test_acc: 1.0\n",
      "Epoch 448, loss: 0.00938427448272705\n",
      "test_acc: 1.0\n",
      "Epoch 449, loss: 0.009370303712785244\n",
      "test_acc: 1.0\n",
      "Epoch 450, loss: 0.009356381371617317\n",
      "test_acc: 1.0\n",
      "Epoch 451, loss: 0.009342514909803867\n",
      "test_acc: 1.0\n",
      "Epoch 452, loss: 0.009328697808086872\n",
      "test_acc: 1.0\n",
      "Epoch 453, loss: 0.00931493379175663\n",
      "test_acc: 1.0\n",
      "Epoch 454, loss: 0.009301220066845417\n",
      "test_acc: 1.0\n",
      "Epoch 455, loss: 0.009287554770708084\n",
      "test_acc: 1.0\n",
      "Epoch 456, loss: 0.009273942559957504\n",
      "test_acc: 1.0\n",
      "Epoch 457, loss: 0.009260381571948528\n",
      "test_acc: 1.0\n",
      "Epoch 458, loss: 0.009246867150068283\n",
      "test_acc: 1.0\n",
      "Epoch 459, loss: 0.009233403950929642\n",
      "test_acc: 1.0\n",
      "Epoch 460, loss: 0.009219990111887455\n",
      "test_acc: 1.0\n",
      "Epoch 461, loss: 0.009206625632941723\n",
      "test_acc: 1.0\n",
      "Epoch 462, loss: 0.009193307720124722\n",
      "test_acc: 1.0\n",
      "Epoch 463, loss: 0.009180042892694473\n",
      "test_acc: 1.0\n",
      "Epoch 464, loss: 0.009166821837425232\n",
      "test_acc: 1.0\n",
      "Epoch 465, loss: 0.00915364921092987\n",
      "test_acc: 1.0\n",
      "Epoch 466, loss: 0.009140527807176113\n",
      "test_acc: 1.0\n",
      "Epoch 467, loss: 0.009127451106905937\n",
      "test_acc: 1.0\n",
      "Epoch 468, loss: 0.009114425629377365\n",
      "test_acc: 1.0\n",
      "Epoch 469, loss: 0.0091014439240098\n",
      "test_acc: 1.0\n",
      "Epoch 470, loss: 0.009088507853448391\n",
      "test_acc: 1.0\n",
      "Epoch 471, loss: 0.009075623005628586\n",
      "test_acc: 1.0\n",
      "Epoch 472, loss: 0.009062782861292362\n",
      "test_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473, loss: 0.009049986489117146\n",
      "test_acc: 1.0\n",
      "Epoch 474, loss: 0.00903723668307066\n",
      "test_acc: 1.0\n",
      "Epoch 475, loss: 0.00902453251183033\n",
      "test_acc: 1.0\n",
      "Epoch 476, loss: 0.009011874906718731\n",
      "test_acc: 1.0\n",
      "Epoch 477, loss: 0.008999262005090714\n",
      "test_acc: 1.0\n",
      "Epoch 478, loss: 0.008986692875623703\n",
      "test_acc: 1.0\n",
      "Epoch 479, loss: 0.008974169380962849\n",
      "test_acc: 1.0\n",
      "Epoch 480, loss: 0.008961688727140427\n",
      "test_acc: 1.0\n",
      "Epoch 481, loss: 0.008949256502091885\n",
      "test_acc: 1.0\n",
      "Epoch 482, loss: 0.008936864323914051\n",
      "test_acc: 1.0\n",
      "Epoch 483, loss: 0.008924517780542374\n",
      "test_acc: 1.0\n",
      "Epoch 484, loss: 0.00891221035271883\n",
      "test_acc: 1.0\n",
      "Epoch 485, loss: 0.008899952284991741\n",
      "test_acc: 1.0\n",
      "Epoch 486, loss: 0.00888773426413536\n",
      "test_acc: 1.0\n",
      "Epoch 487, loss: 0.008875560946762562\n",
      "test_acc: 1.0\n",
      "Epoch 488, loss: 0.00886342953890562\n",
      "test_acc: 1.0\n",
      "Epoch 489, loss: 0.008851341903209686\n",
      "test_acc: 1.0\n",
      "Epoch 490, loss: 0.008839292451739311\n",
      "test_acc: 1.0\n",
      "Epoch 491, loss: 0.008827287703752518\n",
      "test_acc: 1.0\n",
      "Epoch 492, loss: 0.008815324865281582\n",
      "test_acc: 1.0\n",
      "Epoch 493, loss: 0.00880340114235878\n",
      "test_acc: 1.0\n",
      "Epoch 494, loss: 0.008791523054242134\n",
      "test_acc: 1.0\n",
      "Epoch 495, loss: 0.008779682219028473\n",
      "test_acc: 1.0\n",
      "Epoch 496, loss: 0.008767884224653244\n",
      "test_acc: 1.0\n",
      "Epoch 497, loss: 0.008756127208471298\n",
      "test_acc: 1.0\n",
      "Epoch 498, loss: 0.008744410239160061\n",
      "test_acc: 1.0\n",
      "Epoch 499, loss: 0.008732734248042107\n",
      "test_acc: 1.0\n",
      "Epoch 500, loss: 0.008721094578504562\n",
      "test_acc: 1.0\n",
      "Epoch 501, loss: 0.008709501475095749\n",
      "test_acc: 1.0\n",
      "Epoch 502, loss: 0.008697941899299622\n",
      "test_acc: 1.0\n",
      "Epoch 503, loss: 0.008686427026987076\n",
      "test_acc: 1.0\n",
      "Epoch 504, loss: 0.008674945682287216\n",
      "test_acc: 1.0\n",
      "Epoch 505, loss: 0.008663508109748363\n",
      "test_acc: 1.0\n",
      "Epoch 506, loss: 0.008652107790112495\n",
      "test_acc: 1.0\n",
      "Epoch 507, loss: 0.008640746586024761\n",
      "test_acc: 1.0\n",
      "Epoch 508, loss: 0.008629422634840012\n",
      "test_acc: 1.0\n",
      "Epoch 509, loss: 0.008618139661848545\n",
      "test_acc: 1.0\n",
      "Epoch 510, loss: 0.008606892079114914\n",
      "test_acc: 1.0\n",
      "Epoch 511, loss: 0.008595685474574566\n",
      "test_acc: 1.0\n",
      "Epoch 512, loss: 0.00858451146632433\n",
      "test_acc: 1.0\n",
      "Epoch 513, loss: 0.008573380298912525\n",
      "test_acc: 1.0\n",
      "Epoch 514, loss: 0.008562283590435982\n",
      "test_acc: 1.0\n",
      "Epoch 515, loss: 0.008551225997507572\n",
      "test_acc: 1.0\n",
      "Epoch 516, loss: 0.008540204726159573\n",
      "test_acc: 1.0\n",
      "Epoch 517, loss: 0.008529220707714558\n",
      "test_acc: 1.0\n",
      "Epoch 518, loss: 0.008518273010849953\n",
      "test_acc: 1.0\n",
      "Epoch 519, loss: 0.008507360704243183\n",
      "test_acc: 1.0\n",
      "Epoch 520, loss: 0.008496482856571674\n",
      "test_acc: 1.0\n",
      "Epoch 521, loss: 0.008485645987093449\n",
      "test_acc: 1.0\n",
      "Epoch 522, loss: 0.008474842645227909\n",
      "test_acc: 1.0\n",
      "Epoch 523, loss: 0.008464076556265354\n",
      "test_acc: 1.0\n",
      "Epoch 524, loss: 0.00845334492623806\n",
      "test_acc: 1.0\n",
      "Epoch 525, loss: 0.008442647755146027\n",
      "test_acc: 1.0\n",
      "Epoch 526, loss: 0.008431987836956978\n",
      "test_acc: 1.0\n",
      "Epoch 527, loss: 0.008421363309025764\n",
      "test_acc: 1.0\n",
      "Epoch 528, loss: 0.008410772308707237\n",
      "test_acc: 1.0\n",
      "Epoch 529, loss: 0.008400214836001396\n",
      "test_acc: 1.0\n",
      "Epoch 530, loss: 0.00838969461619854\n",
      "test_acc: 1.0\n",
      "Epoch 531, loss: 0.00837920606136322\n",
      "test_acc: 1.0\n",
      "Epoch 532, loss: 0.00836875382810831\n",
      "test_acc: 1.0\n",
      "Epoch 533, loss: 0.008358335122466087\n",
      "test_acc: 1.0\n",
      "Epoch 534, loss: 0.008347950875759125\n",
      "test_acc: 1.0\n",
      "Epoch 535, loss: 0.008337598294019699\n",
      "test_acc: 1.0\n",
      "Epoch 536, loss: 0.008327282033860683\n",
      "test_acc: 1.0\n",
      "Epoch 537, loss: 0.00831699650734663\n",
      "test_acc: 1.0\n",
      "Epoch 538, loss: 0.008306744508445263\n",
      "test_acc: 1.0\n",
      "Epoch 539, loss: 0.00829652976244688\n",
      "test_acc: 1.0\n",
      "Epoch 540, loss: 0.00828634388744831\n",
      "test_acc: 1.0\n",
      "Epoch 541, loss: 0.008276190608739853\n",
      "test_acc: 1.0\n",
      "Epoch 542, loss: 0.008266071788966656\n",
      "test_acc: 1.0\n",
      "Epoch 543, loss: 0.00825598556548357\n",
      "test_acc: 1.0\n",
      "Epoch 544, loss: 0.008245930075645447\n",
      "test_acc: 1.0\n",
      "Epoch 545, loss: 0.00823590811342001\n",
      "test_acc: 1.0\n",
      "Epoch 546, loss: 0.00822591595351696\n",
      "test_acc: 1.0\n",
      "Epoch 547, loss: 0.00821596011519432\n",
      "test_acc: 1.0\n",
      "Epoch 548, loss: 0.00820603221654892\n",
      "test_acc: 1.0\n",
      "Epoch 549, loss: 0.00819613877683878\n",
      "test_acc: 1.0\n",
      "Epoch 550, loss: 0.008186274208128452\n",
      "test_acc: 1.0\n",
      "Epoch 551, loss: 0.008176442235708237\n",
      "test_acc: 1.0\n",
      "Epoch 552, loss: 0.00816663820296526\n",
      "test_acc: 1.0\n",
      "Epoch 553, loss: 0.008156869560480118\n",
      "test_acc: 1.0\n",
      "Epoch 554, loss: 0.008147130720317364\n",
      "test_acc: 1.0\n",
      "Epoch 555, loss: 0.008137422613799572\n",
      "test_acc: 1.0\n",
      "Epoch 556, loss: 0.008127744309604168\n",
      "test_acc: 1.0\n",
      "Epoch 557, loss: 0.008118095807731152\n",
      "test_acc: 1.0\n",
      "Epoch 558, loss: 0.008108478039503098\n",
      "test_acc: 1.0\n",
      "Epoch 559, loss: 0.008098890073597431\n",
      "test_acc: 1.0\n",
      "Epoch 560, loss: 0.008089331910014153\n",
      "test_acc: 1.0\n",
      "Epoch 561, loss: 0.008079804480075836\n",
      "test_acc: 1.0\n",
      "Epoch 562, loss: 0.008070307783782482\n",
      "test_acc: 1.0\n",
      "Epoch 563, loss: 0.008060839027166367\n",
      "test_acc: 1.0\n",
      "Epoch 564, loss: 0.008051399141550064\n",
      "test_acc: 1.0\n",
      "Epoch 565, loss: 0.00804198905825615\n",
      "test_acc: 1.0\n",
      "Epoch 566, loss: 0.008032608777284622\n",
      "test_acc: 1.0\n",
      "Epoch 567, loss: 0.008023258298635483\n",
      "test_acc: 1.0\n",
      "Epoch 568, loss: 0.008013934828341007\n",
      "test_acc: 1.0\n",
      "Epoch 569, loss: 0.008004640229046345\n",
      "test_acc: 1.0\n",
      "Epoch 570, loss: 0.00799537356942892\n",
      "test_acc: 1.0\n",
      "Epoch 571, loss: 0.007986138574779034\n",
      "test_acc: 1.0\n",
      "Epoch 572, loss: 0.00797693058848381\n",
      "test_acc: 1.0\n",
      "Epoch 573, loss: 0.0079677514731884\n",
      "test_acc: 1.0\n",
      "Epoch 574, loss: 0.007958599366247654\n",
      "test_acc: 1.0\n",
      "Epoch 575, loss: 0.007949474267661572\n",
      "test_acc: 1.0\n",
      "Epoch 576, loss: 0.007940378971397877\n",
      "test_acc: 1.0\n",
      "Epoch 577, loss: 0.007931308820843697\n",
      "test_acc: 1.0\n",
      "Epoch 578, loss: 0.007922270335257053\n",
      "test_acc: 1.0\n",
      "Epoch 579, loss: 0.00791325606405735\n",
      "test_acc: 1.0\n",
      "Epoch 580, loss: 0.00790426880121231\n",
      "test_acc: 1.0\n",
      "Epoch 581, loss: 0.007895313203334808\n",
      "test_acc: 1.0\n",
      "Epoch 582, loss: 0.007886378094553947\n",
      "test_acc: 1.0\n",
      "Epoch 583, loss: 0.007877475582063198\n",
      "test_acc: 1.0\n",
      "Epoch 584, loss: 0.007868598215281963\n",
      "test_acc: 1.0\n",
      "Epoch 585, loss: 0.007859745062887669\n",
      "test_acc: 1.0\n",
      "Epoch 586, loss: 0.007850919850170612\n",
      "test_acc: 1.0\n",
      "Epoch 587, loss: 0.007842122577130795\n",
      "test_acc: 1.0\n",
      "Epoch 588, loss: 0.007833349518477917\n",
      "test_acc: 1.0\n",
      "Epoch 589, loss: 0.007824604399502277\n",
      "test_acc: 1.0\n",
      "Epoch 590, loss: 0.007815885357558727\n",
      "test_acc: 1.0\n",
      "Epoch 591, loss: 0.0078071909956634045\n",
      "test_acc: 1.0\n",
      "Epoch 592, loss: 0.007798522710800171\n",
      "test_acc: 1.0\n",
      "Epoch 593, loss: 0.007789880968630314\n",
      "test_acc: 1.0\n",
      "Epoch 594, loss: 0.00778126809746027\n",
      "test_acc: 1.0\n",
      "Epoch 595, loss: 0.007772676646709442\n",
      "test_acc: 1.0\n",
      "Epoch 596, loss: 0.0077641126699745655\n",
      "test_acc: 1.0\n",
      "Epoch 597, loss: 0.00775557104498148\n",
      "test_acc: 1.0\n",
      "Epoch 598, loss: 0.007747057359665632\n",
      "test_acc: 1.0\n",
      "Epoch 599, loss: 0.007738570217043161\n",
      "test_acc: 1.0\n",
      "Epoch 600, loss: 0.007730104960501194\n",
      "test_acc: 1.0\n",
      "Epoch 601, loss: 0.0077216667123138905\n",
      "test_acc: 1.0\n",
      "Epoch 602, loss: 0.007713253144174814\n",
      "test_acc: 1.0\n",
      "Epoch 603, loss: 0.0077048614621162415\n",
      "test_acc: 1.0\n",
      "Epoch 604, loss: 0.007696496322751045\n",
      "test_acc: 1.0\n",
      "Epoch 605, loss: 0.007688155397772789\n",
      "test_acc: 1.0\n",
      "Epoch 606, loss: 0.0076798382215201855\n",
      "test_acc: 1.0\n",
      "Epoch 607, loss: 0.007671545725315809\n",
      "test_acc: 1.0\n",
      "Epoch 608, loss: 0.00766327977180481\n",
      "test_acc: 1.0\n",
      "Epoch 609, loss: 0.007655034307390451\n",
      "test_acc: 1.0\n",
      "Epoch 610, loss: 0.0076468163169920444\n",
      "test_acc: 1.0\n",
      "Epoch 611, loss: 0.007638620212674141\n",
      "test_acc: 1.0\n",
      "Epoch 612, loss: 0.007630447391420603\n",
      "test_acc: 1.0\n",
      "Epoch 613, loss: 0.007622296456247568\n",
      "test_acc: 1.0\n",
      "Epoch 614, loss: 0.00761417206376791\n",
      "test_acc: 1.0\n",
      "Epoch 615, loss: 0.007606070954352617\n",
      "test_acc: 1.0\n",
      "Epoch 616, loss: 0.007597992662340403\n",
      "test_acc: 1.0\n",
      "Epoch 617, loss: 0.007589938119053841\n",
      "test_acc: 1.0\n",
      "Epoch 618, loss: 0.0075819045305252075\n",
      "test_acc: 1.0\n",
      "Epoch 619, loss: 0.00757389422506094\n",
      "test_acc: 1.0\n",
      "Epoch 620, loss: 0.007565910462290049\n",
      "test_acc: 1.0\n",
      "Epoch 621, loss: 0.007557948585599661\n",
      "test_acc: 1.0\n",
      "Epoch 622, loss: 0.0075500053353607655\n",
      "test_acc: 1.0\n",
      "Epoch 623, loss: 0.007542086765170097\n",
      "test_acc: 1.0\n",
      "Epoch 624, loss: 0.0075341928750276566\n",
      "test_acc: 1.0\n",
      "Epoch 625, loss: 0.007526318076997995\n",
      "test_acc: 1.0\n",
      "Epoch 626, loss: 0.007518470287322998\n",
      "test_acc: 1.0\n",
      "Epoch 627, loss: 0.0075106387957930565\n",
      "test_acc: 1.0\n",
      "Epoch 628, loss: 0.0075028324499726295\n",
      "test_acc: 1.0\n",
      "Epoch 629, loss: 0.00749505078420043\n",
      "test_acc: 1.0\n",
      "Epoch 630, loss: 0.007487287744879723\n",
      "test_acc: 1.0\n",
      "Epoch 631, loss: 0.007479545194655657\n",
      "test_acc: 1.0\n",
      "Epoch 632, loss: 0.007471827790141106\n",
      "test_acc: 1.0\n",
      "Epoch 633, loss: 0.007464129012078047\n",
      "test_acc: 1.0\n",
      "Epoch 634, loss: 0.007456454914063215\n",
      "test_acc: 1.0\n",
      "Epoch 635, loss: 0.007448797579854727\n",
      "test_acc: 1.0\n",
      "Epoch 636, loss: 0.0074411663226783276\n",
      "test_acc: 1.0\n",
      "Epoch 637, loss: 0.0074335550889372826\n",
      "test_acc: 1.0\n",
      "Epoch 638, loss: 0.007425969000905752\n",
      "test_acc: 1.0\n",
      "Epoch 639, loss: 0.007418396417051554\n",
      "test_acc: 1.0\n",
      "Epoch 640, loss: 0.00741084897890687\n",
      "test_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641, loss: 0.007403323892503977\n",
      "test_acc: 1.0\n",
      "Epoch 642, loss: 0.007395815569907427\n",
      "test_acc: 1.0\n",
      "Epoch 643, loss: 0.007388330064713955\n",
      "test_acc: 1.0\n",
      "Epoch 644, loss: 0.0073808664456009865\n",
      "test_acc: 1.0\n",
      "Epoch 645, loss: 0.007373422384262085\n",
      "test_acc: 1.0\n",
      "Epoch 646, loss: 0.007366000674664974\n",
      "test_acc: 1.0\n",
      "Epoch 647, loss: 0.007358596660196781\n",
      "test_acc: 1.0\n",
      "Epoch 648, loss: 0.00735121313482523\n",
      "test_acc: 1.0\n",
      "Epoch 649, loss: 0.007343851029872894\n",
      "test_acc: 1.0\n",
      "Epoch 650, loss: 0.007336508948355913\n",
      "test_acc: 1.0\n",
      "Epoch 651, loss: 0.007329187355935574\n",
      "test_acc: 1.0\n",
      "Epoch 652, loss: 0.0073218876495957375\n",
      "test_acc: 1.0\n",
      "Epoch 653, loss: 0.0073146033100783825\n",
      "test_acc: 1.0\n",
      "Epoch 654, loss: 0.007307338062673807\n",
      "test_acc: 1.0\n",
      "Epoch 655, loss: 0.007300098892301321\n",
      "test_acc: 1.0\n",
      "Epoch 656, loss: 0.007292876485735178\n",
      "test_acc: 1.0\n",
      "Epoch 657, loss: 0.007285672705620527\n",
      "test_acc: 1.0\n",
      "Epoch 658, loss: 0.007278488017618656\n",
      "test_acc: 1.0\n",
      "Epoch 659, loss: 0.007271323818713427\n",
      "test_acc: 1.0\n",
      "Epoch 660, loss: 0.007264178711920977\n",
      "test_acc: 1.0\n",
      "Epoch 661, loss: 0.007257055025547743\n",
      "test_acc: 1.0\n",
      "Epoch 662, loss: 0.007249949034303427\n",
      "test_acc: 1.0\n",
      "Epoch 663, loss: 0.007242861669510603\n",
      "test_acc: 1.0\n",
      "Epoch 664, loss: 0.007235793396830559\n",
      "test_acc: 1.0\n",
      "Epoch 665, loss: 0.007228745147585869\n",
      "test_acc: 1.0\n",
      "Epoch 666, loss: 0.007221715524792671\n",
      "test_acc: 1.0\n",
      "Epoch 667, loss: 0.007214703597128391\n",
      "test_acc: 1.0\n",
      "Epoch 668, loss: 0.0072077116928994656\n",
      "test_acc: 1.0\n",
      "Epoch 669, loss: 0.007200736086815596\n",
      "test_acc: 1.0\n",
      "Epoch 670, loss: 0.0071937814354896545\n",
      "test_acc: 1.0\n",
      "Epoch 671, loss: 0.007186845876276493\n",
      "test_acc: 1.0\n",
      "Epoch 672, loss: 0.007179927546530962\n",
      "test_acc: 1.0\n",
      "Epoch 673, loss: 0.007173029240220785\n",
      "test_acc: 1.0\n",
      "Epoch 674, loss: 0.007166145369410515\n",
      "test_acc: 1.0\n",
      "Epoch 675, loss: 0.007159284316003323\n",
      "test_acc: 1.0\n",
      "Epoch 676, loss: 0.00715243723243475\n",
      "test_acc: 1.0\n",
      "Epoch 677, loss: 0.0071456111036241055\n",
      "test_acc: 1.0\n",
      "Epoch 678, loss: 0.007138798478990793\n",
      "test_acc: 1.0\n",
      "Epoch 679, loss: 0.007132008671760559\n",
      "test_acc: 1.0\n",
      "Epoch 680, loss: 0.007125235162675381\n",
      "test_acc: 1.0\n",
      "Epoch 681, loss: 0.007118478417396545\n",
      "test_acc: 1.0\n",
      "Epoch 682, loss: 0.007111741229891777\n",
      "test_acc: 1.0\n",
      "Epoch 683, loss: 0.00710501940920949\n",
      "test_acc: 1.0\n",
      "Epoch 684, loss: 0.007098320405930281\n",
      "test_acc: 1.0\n",
      "Epoch 685, loss: 0.00709163211286068\n",
      "test_acc: 1.0\n",
      "Epoch 686, loss: 0.007084968034178019\n",
      "test_acc: 1.0\n",
      "Epoch 687, loss: 0.007078316528350115\n",
      "test_acc: 1.0\n",
      "Epoch 688, loss: 0.007071683648973703\n",
      "test_acc: 1.0\n",
      "Epoch 689, loss: 0.007065069396048784\n",
      "test_acc: 1.0\n",
      "Epoch 690, loss: 0.007058471441268921\n",
      "test_acc: 1.0\n",
      "Epoch 691, loss: 0.007051890715956688\n",
      "test_acc: 1.0\n",
      "Epoch 692, loss: 0.007045325357466936\n",
      "test_acc: 1.0\n",
      "Epoch 693, loss: 0.007038777694106102\n",
      "test_acc: 1.0\n",
      "Epoch 694, loss: 0.007032247260212898\n",
      "test_acc: 1.0\n",
      "Epoch 695, loss: 0.007025733590126038\n",
      "test_acc: 1.0\n",
      "Epoch 696, loss: 0.007019234821200371\n",
      "test_acc: 1.0\n",
      "Epoch 697, loss: 0.007012755610048771\n",
      "test_acc: 1.0\n",
      "Epoch 698, loss: 0.007006289903074503\n",
      "test_acc: 1.0\n",
      "Epoch 699, loss: 0.0069998460821807384\n",
      "test_acc: 1.0\n",
      "Epoch 700, loss: 0.006993414834141731\n",
      "test_acc: 1.0\n",
      "Epoch 701, loss: 0.006987002212554216\n",
      "test_acc: 1.0\n",
      "Epoch 702, loss: 0.006980604492127895\n",
      "test_acc: 1.0\n",
      "Epoch 703, loss: 0.006974222604185343\n",
      "test_acc: 1.0\n",
      "Epoch 704, loss: 0.006967857480049133\n",
      "test_acc: 1.0\n",
      "Epoch 705, loss: 0.006961509585380554\n",
      "test_acc: 1.0\n",
      "Epoch 706, loss: 0.006955175660550594\n",
      "test_acc: 1.0\n",
      "Epoch 707, loss: 0.006948860362172127\n",
      "test_acc: 1.0\n",
      "Epoch 708, loss: 0.006942559499293566\n",
      "test_acc: 1.0\n",
      "Epoch 709, loss: 0.006936274468898773\n",
      "test_acc: 1.0\n",
      "Epoch 710, loss: 0.006930006202310324\n",
      "test_acc: 1.0\n",
      "Epoch 711, loss: 0.006923755165189505\n",
      "test_acc: 1.0\n",
      "Epoch 712, loss: 0.006917515769600868\n",
      "test_acc: 1.0\n",
      "Epoch 713, loss: 0.0069112954661250114\n",
      "test_acc: 1.0\n",
      "Epoch 714, loss: 0.006905087269842625\n",
      "test_acc: 1.0\n",
      "Epoch 715, loss: 0.006898896768689156\n",
      "test_acc: 1.0\n",
      "Epoch 716, loss: 0.006892723497003317\n",
      "test_acc: 1.0\n",
      "Epoch 717, loss: 0.006886563263833523\n",
      "test_acc: 1.0\n",
      "Epoch 718, loss: 0.00688041839748621\n",
      "test_acc: 1.0\n",
      "Epoch 719, loss: 0.006874291691929102\n",
      "test_acc: 1.0\n",
      "Epoch 720, loss: 0.006868180353194475\n",
      "test_acc: 1.0\n",
      "Epoch 721, loss: 0.006862080655992031\n",
      "test_acc: 1.0\n",
      "Epoch 722, loss: 0.006855999585241079\n",
      "test_acc: 1.0\n",
      "Epoch 723, loss: 0.006849932949990034\n",
      "test_acc: 1.0\n",
      "Epoch 724, loss: 0.006843878887593746\n",
      "test_acc: 1.0\n",
      "Epoch 725, loss: 0.006837841589003801\n",
      "test_acc: 1.0\n",
      "Epoch 726, loss: 0.006831817328929901\n",
      "test_acc: 1.0\n",
      "Epoch 727, loss: 0.006825811695307493\n",
      "test_acc: 1.0\n",
      "Epoch 728, loss: 0.006819818634539843\n",
      "test_acc: 1.0\n",
      "Epoch 729, loss: 0.006813840940594673\n",
      "test_acc: 1.0\n",
      "Epoch 730, loss: 0.006807876285165548\n",
      "test_acc: 1.0\n",
      "Epoch 731, loss: 0.006801927462220192\n",
      "test_acc: 1.0\n",
      "Epoch 732, loss: 0.0067959921434521675\n",
      "test_acc: 1.0\n",
      "Epoch 733, loss: 0.0067900726571679115\n",
      "test_acc: 1.0\n",
      "Epoch 734, loss: 0.006784169003367424\n",
      "test_acc: 1.0\n",
      "Epoch 735, loss: 0.006778276525437832\n",
      "test_acc: 1.0\n",
      "Epoch 736, loss: 0.0067724017426371574\n",
      "test_acc: 1.0\n",
      "Epoch 737, loss: 0.006766539998352528\n",
      "test_acc: 1.0\n",
      "Epoch 738, loss: 0.006760692223906517\n",
      "test_acc: 1.0\n",
      "Epoch 739, loss: 0.006754858419299126\n",
      "test_acc: 1.0\n",
      "Epoch 740, loss: 0.006749039515852928\n",
      "test_acc: 1.0\n",
      "Epoch 741, loss: 0.006743232253938913\n",
      "test_acc: 1.0\n",
      "Epoch 742, loss: 0.006737442687153816\n",
      "test_acc: 1.0\n",
      "Epoch 743, loss: 0.0067316684871912\n",
      "test_acc: 1.0\n",
      "Epoch 744, loss: 0.0067259036004543304\n",
      "test_acc: 1.0\n",
      "Epoch 745, loss: 0.006720155011862516\n",
      "test_acc: 1.0\n",
      "Epoch 746, loss: 0.00671441899612546\n",
      "test_acc: 1.0\n",
      "Epoch 747, loss: 0.0067086974158883095\n",
      "test_acc: 1.0\n",
      "Epoch 748, loss: 0.006702991668134928\n",
      "test_acc: 1.0\n",
      "Epoch 749, loss: 0.006697297561913729\n",
      "test_acc: 1.0\n",
      "Epoch 750, loss: 0.006691616959869862\n",
      "test_acc: 1.0\n",
      "Epoch 751, loss: 0.006685951724648476\n",
      "test_acc: 1.0\n",
      "Epoch 752, loss: 0.006680297665297985\n",
      "test_acc: 1.0\n",
      "Epoch 753, loss: 0.006674658041447401\n",
      "test_acc: 1.0\n",
      "Epoch 754, loss: 0.006669031921774149\n",
      "test_acc: 1.0\n",
      "Epoch 755, loss: 0.006663420237600803\n",
      "test_acc: 1.0\n",
      "Epoch 756, loss: 0.006657817400991917\n",
      "test_acc: 1.0\n",
      "Epoch 757, loss: 0.006652234587818384\n",
      "test_acc: 1.0\n",
      "Epoch 758, loss: 0.0066466606222093105\n",
      "test_acc: 1.0\n",
      "Epoch 759, loss: 0.0066410996951162815\n",
      "test_acc: 1.0\n",
      "Epoch 760, loss: 0.006635557860136032\n",
      "test_acc: 1.0\n",
      "Epoch 761, loss: 0.00663002161309123\n",
      "test_acc: 1.0\n",
      "Epoch 762, loss: 0.006624502595514059\n",
      "test_acc: 1.0\n",
      "Epoch 763, loss: 0.006618996616452932\n",
      "test_acc: 1.0\n",
      "Epoch 764, loss: 0.0066134994849562645\n",
      "test_acc: 1.0\n",
      "Epoch 765, loss: 0.006608020048588514\n",
      "test_acc: 1.0\n",
      "Epoch 766, loss: 0.0066025531850755215\n",
      "test_acc: 1.0\n",
      "Epoch 767, loss: 0.006597097497433424\n",
      "test_acc: 1.0\n",
      "Epoch 768, loss: 0.006591654382646084\n",
      "test_acc: 1.0\n",
      "Epoch 769, loss: 0.006586225237697363\n",
      "test_acc: 1.0\n",
      "Epoch 770, loss: 0.006580807734280825\n",
      "test_acc: 1.0\n",
      "Epoch 771, loss: 0.006575403269380331\n",
      "test_acc: 1.0\n",
      "Epoch 772, loss: 0.006570011842995882\n",
      "test_acc: 1.0\n",
      "Epoch 773, loss: 0.006564633920788765\n",
      "test_acc: 1.0\n",
      "Epoch 774, loss: 0.006559267174452543\n",
      "test_acc: 1.0\n",
      "Epoch 775, loss: 0.006553913000971079\n",
      "test_acc: 1.0\n",
      "Epoch 776, loss: 0.006548568606376648\n",
      "test_acc: 1.0\n",
      "Epoch 777, loss: 0.006543240509927273\n",
      "test_acc: 1.0\n",
      "Epoch 778, loss: 0.006537923123687506\n",
      "test_acc: 1.0\n",
      "Epoch 779, loss: 0.006532620172947645\n",
      "test_acc: 1.0\n",
      "Epoch 780, loss: 0.006527325138449669\n",
      "test_acc: 1.0\n",
      "Epoch 781, loss: 0.006522046402096748\n",
      "test_acc: 1.0\n",
      "Epoch 782, loss: 0.006516780238598585\n",
      "test_acc: 1.0\n",
      "Epoch 783, loss: 0.006511523388326168\n",
      "test_acc: 1.0\n",
      "Epoch 784, loss: 0.006506280042231083\n",
      "test_acc: 1.0\n",
      "Epoch 785, loss: 0.006501046475023031\n",
      "test_acc: 1.0\n",
      "Epoch 786, loss: 0.006495824549347162\n",
      "test_acc: 1.0\n",
      "Epoch 787, loss: 0.006490617990493774\n",
      "test_acc: 1.0\n",
      "Epoch 788, loss: 0.006485421676188707\n",
      "test_acc: 1.0\n",
      "Epoch 789, loss: 0.00648023746907711\n",
      "test_acc: 1.0\n",
      "Epoch 790, loss: 0.0064750672318041325\n",
      "test_acc: 1.0\n",
      "Epoch 791, loss: 0.006469905376434326\n",
      "test_acc: 1.0\n",
      "Epoch 792, loss: 0.006464757956564426\n",
      "test_acc: 1.0\n",
      "Epoch 793, loss: 0.00645962031558156\n",
      "test_acc: 1.0\n",
      "Epoch 794, loss: 0.006454493384808302\n",
      "test_acc: 1.0\n",
      "Epoch 795, loss: 0.006449380423873663\n",
      "test_acc: 1.0\n",
      "Epoch 796, loss: 0.0064442772418260574\n",
      "test_acc: 1.0\n",
      "Epoch 797, loss: 0.0064391884952783585\n",
      "test_acc: 1.0\n",
      "Epoch 798, loss: 0.006434108596295118\n",
      "test_acc: 1.0\n",
      "Epoch 799, loss: 0.00642904220148921\n",
      "test_acc: 1.0\n",
      "Epoch 800, loss: 0.006423986982554197\n",
      "test_acc: 1.0\n",
      "Epoch 801, loss: 0.006418942473828793\n",
      "test_acc: 1.0\n",
      "Epoch 802, loss: 0.006413909140974283\n",
      "test_acc: 1.0\n",
      "Epoch 803, loss: 0.006408888380974531\n",
      "test_acc: 1.0\n",
      "Epoch 804, loss: 0.006403878331184387\n",
      "test_acc: 1.0\n",
      "Epoch 805, loss: 0.006398876663297415\n",
      "test_acc: 1.0\n",
      "Epoch 806, loss: 0.006393888033926487\n",
      "test_acc: 1.0\n",
      "Epoch 807, loss: 0.006388910114765167\n",
      "test_acc: 1.0\n",
      "Epoch 808, loss: 0.006383947096765041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 1.0\n",
      "Epoch 809, loss: 0.006378990598022938\n",
      "test_acc: 1.0\n",
      "Epoch 810, loss: 0.006374046206474304\n",
      "test_acc: 1.0\n",
      "Epoch 811, loss: 0.006369112990796566\n",
      "test_acc: 1.0\n",
      "Epoch 812, loss: 0.006364191882312298\n",
      "test_acc: 1.0\n",
      "Epoch 813, loss: 0.006359279155731201\n",
      "test_acc: 1.0\n",
      "Epoch 814, loss: 0.0063543785363435745\n",
      "test_acc: 1.0\n",
      "Epoch 815, loss: 0.006349490489810705\n",
      "test_acc: 1.0\n",
      "Epoch 816, loss: 0.006344611290842295\n",
      "test_acc: 1.0\n",
      "Epoch 817, loss: 0.00633974326774478\n",
      "test_acc: 1.0\n",
      "Epoch 818, loss: 0.006334889214485884\n",
      "test_acc: 1.0\n",
      "Epoch 819, loss: 0.00633004168048501\n",
      "test_acc: 1.0\n",
      "Epoch 820, loss: 0.006325206719338894\n",
      "test_acc: 1.0\n",
      "Epoch 821, loss: 0.006320382468402386\n",
      "test_acc: 1.0\n",
      "Epoch 822, loss: 0.0063155656680464745\n",
      "test_acc: 1.0\n",
      "Epoch 823, loss: 0.0063107628375291824\n",
      "test_acc: 1.0\n",
      "Epoch 824, loss: 0.006305971182882786\n",
      "test_acc: 1.0\n",
      "Epoch 825, loss: 0.006301188841462135\n",
      "test_acc: 1.0\n",
      "Epoch 826, loss: 0.006296415813267231\n",
      "test_acc: 1.0\n",
      "Epoch 827, loss: 0.006291654426604509\n",
      "test_acc: 1.0\n",
      "Epoch 828, loss: 0.006286902818828821\n",
      "test_acc: 1.0\n",
      "Epoch 829, loss: 0.006282162386924028\n",
      "test_acc: 1.0\n",
      "Epoch 830, loss: 0.006277431733906269\n",
      "test_acc: 1.0\n",
      "Epoch 831, loss: 0.006272710859775543\n",
      "test_acc: 1.0\n",
      "Epoch 832, loss: 0.006268000230193138\n",
      "test_acc: 1.0\n",
      "Epoch 833, loss: 0.006263299845159054\n",
      "test_acc: 1.0\n",
      "Epoch 834, loss: 0.006258609239012003\n",
      "test_acc: 1.0\n",
      "Epoch 835, loss: 0.006253930740058422\n",
      "test_acc: 1.0\n",
      "Epoch 836, loss: 0.006249260623008013\n",
      "test_acc: 1.0\n",
      "Epoch 837, loss: 0.006244602147489786\n",
      "test_acc: 1.0\n",
      "Epoch 838, loss: 0.00623994879424572\n",
      "test_acc: 1.0\n",
      "Epoch 839, loss: 0.006235314533114433\n",
      "test_acc: 1.0\n",
      "Epoch 840, loss: 0.00623068492859602\n",
      "test_acc: 1.0\n",
      "Epoch 841, loss: 0.006226064637303352\n",
      "test_acc: 1.0\n",
      "Epoch 842, loss: 0.006221453659236431\n",
      "test_acc: 1.0\n",
      "Epoch 843, loss: 0.006216853857040405\n",
      "test_acc: 1.0\n",
      "Epoch 844, loss: 0.0062122647650539875\n",
      "test_acc: 1.0\n",
      "Epoch 845, loss: 0.006207686383277178\n",
      "test_acc: 1.0\n",
      "Epoch 846, loss: 0.0062031131237745285\n",
      "test_acc: 1.0\n",
      "Epoch 847, loss: 0.006198551971465349\n",
      "test_acc: 1.0\n",
      "Epoch 848, loss: 0.00619400292634964\n",
      "test_acc: 1.0\n",
      "Epoch 849, loss: 0.00618946086615324\n",
      "test_acc: 1.0\n",
      "Epoch 850, loss: 0.006184927187860012\n",
      "test_acc: 1.0\n",
      "Epoch 851, loss: 0.0061804065480828285\n",
      "test_acc: 1.0\n",
      "Epoch 852, loss: 0.0061758956871926785\n",
      "test_acc: 1.0\n",
      "Epoch 853, loss: 0.006171392276883125\n",
      "test_acc: 1.0\n",
      "Epoch 854, loss: 0.006166898645460606\n",
      "test_acc: 1.0\n",
      "Epoch 855, loss: 0.006162416655570269\n",
      "test_acc: 1.0\n",
      "Epoch 856, loss: 0.006157941184937954\n",
      "test_acc: 1.0\n",
      "Epoch 857, loss: 0.006153476890176535\n",
      "test_acc: 1.0\n",
      "Epoch 858, loss: 0.006149018183350563\n",
      "test_acc: 1.0\n",
      "Epoch 859, loss: 0.006144573912024498\n",
      "test_acc: 1.0\n",
      "Epoch 860, loss: 0.006140137556940317\n",
      "test_acc: 1.0\n",
      "Epoch 861, loss: 0.006135711446404457\n",
      "test_acc: 1.0\n",
      "Epoch 862, loss: 0.006131292320787907\n",
      "test_acc: 1.0\n",
      "Epoch 863, loss: 0.006126882042735815\n",
      "test_acc: 1.0\n",
      "Epoch 864, loss: 0.006122481543570757\n",
      "test_acc: 1.0\n",
      "Epoch 865, loss: 0.006118092220276594\n",
      "test_acc: 1.0\n",
      "Epoch 866, loss: 0.006113709881901741\n",
      "test_acc: 1.0\n",
      "Epoch 867, loss: 0.006109339185059071\n",
      "test_acc: 1.0\n",
      "Epoch 868, loss: 0.0061049750074744225\n",
      "test_acc: 1.0\n",
      "Epoch 869, loss: 0.006100622471421957\n",
      "test_acc: 1.0\n",
      "Epoch 870, loss: 0.00609627878293395\n",
      "test_acc: 1.0\n",
      "Epoch 871, loss: 0.006091942545026541\n",
      "test_acc: 1.0\n",
      "Epoch 872, loss: 0.006087614223361015\n",
      "test_acc: 1.0\n",
      "Epoch 873, loss: 0.006083295680582523\n",
      "test_acc: 1.0\n",
      "Epoch 874, loss: 0.006078985519707203\n",
      "test_acc: 1.0\n",
      "Epoch 875, loss: 0.006074687000364065\n",
      "test_acc: 1.0\n",
      "Epoch 876, loss: 0.006070395931601524\n",
      "test_acc: 1.0\n",
      "Epoch 877, loss: 0.006066114641726017\n",
      "test_acc: 1.0\n",
      "Epoch 878, loss: 0.006061838939785957\n",
      "test_acc: 1.0\n",
      "Epoch 879, loss: 0.00605757487937808\n",
      "test_acc: 1.0\n",
      "Epoch 880, loss: 0.006053318735212088\n",
      "test_acc: 1.0\n",
      "Epoch 881, loss: 0.006049070041626692\n",
      "test_acc: 1.0\n",
      "Epoch 882, loss: 0.006044831592589617\n",
      "test_acc: 1.0\n",
      "Epoch 883, loss: 0.006040604785084724\n",
      "test_acc: 1.0\n",
      "Epoch 884, loss: 0.006036380305886269\n",
      "test_acc: 1.0\n",
      "Epoch 885, loss: 0.006032170727849007\n",
      "test_acc: 1.0\n",
      "Epoch 886, loss: 0.006027965806424618\n",
      "test_acc: 1.0\n",
      "Epoch 887, loss: 0.006023770198225975\n",
      "test_acc: 1.0\n",
      "Epoch 888, loss: 0.006019582971930504\n",
      "test_acc: 1.0\n",
      "Epoch 889, loss: 0.0060154045931994915\n",
      "test_acc: 1.0\n",
      "Epoch 890, loss: 0.0060112327337265015\n",
      "test_acc: 1.0\n",
      "Epoch 891, loss: 0.006007071118801832\n",
      "test_acc: 1.0\n",
      "Epoch 892, loss: 0.006002921145409346\n",
      "test_acc: 1.0\n",
      "Epoch 893, loss: 0.005998772569000721\n",
      "test_acc: 1.0\n",
      "Epoch 894, loss: 0.005994635634124279\n",
      "test_acc: 1.0\n",
      "Epoch 895, loss: 0.0059905098751187325\n",
      "test_acc: 1.0\n",
      "Epoch 896, loss: 0.005986390635371208\n",
      "test_acc: 1.0\n",
      "Epoch 897, loss: 0.005982277914881706\n",
      "test_acc: 1.0\n",
      "Epoch 898, loss: 0.005978174973279238\n",
      "test_acc: 1.0\n",
      "Epoch 899, loss: 0.0059740799479186535\n",
      "test_acc: 1.0\n",
      "Epoch 900, loss: 0.005969993770122528\n",
      "test_acc: 1.0\n",
      "Epoch 901, loss: 0.005965915042907\n",
      "test_acc: 1.0\n",
      "Epoch 902, loss: 0.00596184516325593\n",
      "test_acc: 1.0\n",
      "Epoch 903, loss: 0.005957784131169319\n",
      "test_acc: 1.0\n",
      "Epoch 904, loss: 0.005953730084002018\n",
      "test_acc: 1.0\n",
      "Epoch 905, loss: 0.005949684418737888\n",
      "test_acc: 1.0\n",
      "Epoch 906, loss: 0.005945645272731781\n",
      "test_acc: 1.0\n",
      "Epoch 907, loss: 0.005941617768257856\n",
      "test_acc: 1.0\n",
      "Epoch 908, loss: 0.0059375944547355175\n",
      "test_acc: 1.0\n",
      "Epoch 909, loss: 0.005933580920100212\n",
      "test_acc: 1.0\n",
      "Epoch 910, loss: 0.005929575767368078\n",
      "test_acc: 1.0\n",
      "Epoch 911, loss: 0.005925576668232679\n",
      "test_acc: 1.0\n",
      "Epoch 912, loss: 0.005921587347984314\n",
      "test_acc: 1.0\n",
      "Epoch 913, loss: 0.005917604546993971\n",
      "test_acc: 1.0\n",
      "Epoch 914, loss: 0.005913631059229374\n",
      "test_acc: 1.0\n",
      "Epoch 915, loss: 0.005909664090722799\n",
      "test_acc: 1.0\n",
      "Epoch 916, loss: 0.0059057059697806835\n",
      "test_acc: 1.0\n",
      "Epoch 917, loss: 0.005901754833757877\n",
      "test_acc: 1.0\n",
      "Epoch 918, loss: 0.005897815339267254\n",
      "test_acc: 1.0\n",
      "Epoch 919, loss: 0.005893876310437918\n",
      "test_acc: 1.0\n",
      "Epoch 920, loss: 0.0058899493888020515\n",
      "test_acc: 1.0\n",
      "Epoch 921, loss: 0.005886028986424208\n",
      "test_acc: 1.0\n",
      "Epoch 922, loss: 0.005882117431610823\n",
      "test_acc: 1.0\n",
      "Epoch 923, loss: 0.005878214258700609\n",
      "test_acc: 1.0\n",
      "Epoch 924, loss: 0.005874316673725843\n",
      "test_acc: 1.0\n",
      "Epoch 925, loss: 0.0058704279363155365\n",
      "test_acc: 1.0\n",
      "Epoch 926, loss: 0.005866547580808401\n",
      "test_acc: 1.0\n",
      "Epoch 927, loss: 0.005862672347575426\n",
      "test_acc: 1.0\n",
      "Epoch 928, loss: 0.00585880596190691\n",
      "test_acc: 1.0\n",
      "Epoch 929, loss: 0.005854947958141565\n",
      "test_acc: 1.0\n",
      "Epoch 930, loss: 0.0058510941453278065\n",
      "test_acc: 1.0\n",
      "Epoch 931, loss: 0.00584725197404623\n",
      "test_acc: 1.0\n",
      "Epoch 932, loss: 0.005843415390700102\n",
      "test_acc: 1.0\n",
      "Epoch 933, loss: 0.005839584395289421\n",
      "test_acc: 1.0\n",
      "Epoch 934, loss: 0.005835761781781912\n",
      "test_acc: 1.0\n",
      "Epoch 935, loss: 0.005831948481500149\n",
      "test_acc: 1.0\n",
      "Epoch 936, loss: 0.005828142166137695\n",
      "test_acc: 1.0\n",
      "Epoch 937, loss: 0.005824340507388115\n",
      "test_acc: 1.0\n",
      "Epoch 938, loss: 0.0058205509558320045\n",
      "test_acc: 1.0\n",
      "Epoch 939, loss: 0.005816766992211342\n",
      "test_acc: 1.0\n",
      "Epoch 940, loss: 0.005812986753880978\n",
      "test_acc: 1.0\n",
      "Epoch 941, loss: 0.005809218622744083\n",
      "test_acc: 1.0\n",
      "Epoch 942, loss: 0.005805454216897488\n",
      "test_acc: 1.0\n",
      "Epoch 943, loss: 0.005801699124276638\n",
      "test_acc: 1.0\n",
      "Epoch 944, loss: 0.005797950085252523\n",
      "test_acc: 1.0\n",
      "Epoch 945, loss: 0.005794210825115442\n",
      "test_acc: 1.0\n",
      "Epoch 946, loss: 0.005790474358946085\n",
      "test_acc: 1.0\n",
      "Epoch 947, loss: 0.0057867467403411865\n",
      "test_acc: 1.0\n",
      "Epoch 948, loss: 0.00578302564099431\n",
      "test_acc: 1.0\n",
      "Epoch 949, loss: 0.005779310129582882\n",
      "test_acc: 1.0\n",
      "Epoch 950, loss: 0.0057756053283810616\n",
      "test_acc: 1.0\n",
      "Epoch 951, loss: 0.005771907512098551\n",
      "test_acc: 1.0\n",
      "Epoch 952, loss: 0.005768215283751488\n",
      "test_acc: 1.0\n",
      "Epoch 953, loss: 0.005764529574662447\n",
      "test_acc: 1.0\n",
      "Epoch 954, loss: 0.0057608517818152905\n",
      "test_acc: 1.0\n",
      "Epoch 955, loss: 0.0057571809738874435\n",
      "test_acc: 1.0\n",
      "Epoch 956, loss: 0.005753518082201481\n",
      "test_acc: 1.0\n",
      "Epoch 957, loss: 0.005749858915805817\n",
      "test_acc: 1.0\n",
      "Epoch 958, loss: 0.005746209993958473\n",
      "test_acc: 1.0\n",
      "Epoch 959, loss: 0.005742565728724003\n",
      "test_acc: 1.0\n",
      "Epoch 960, loss: 0.005738929845392704\n",
      "test_acc: 1.0\n",
      "Epoch 961, loss: 0.005735298618674278\n",
      "test_acc: 1.0\n",
      "Epoch 962, loss: 0.005731677170842886\n",
      "test_acc: 1.0\n",
      "Epoch 963, loss: 0.005728061776608229\n",
      "test_acc: 1.0\n",
      "Epoch 964, loss: 0.005724450573325157\n",
      "test_acc: 1.0\n",
      "Epoch 965, loss: 0.005720849614590406\n",
      "test_acc: 1.0\n",
      "Epoch 966, loss: 0.005717251915484667\n",
      "test_acc: 1.0\n",
      "Epoch 967, loss: 0.005713663995265961\n",
      "test_acc: 1.0\n",
      "Epoch 968, loss: 0.0057100835256278515\n",
      "test_acc: 1.0\n",
      "Epoch 969, loss: 0.005706506315618753\n",
      "test_acc: 1.0\n",
      "Epoch 970, loss: 0.005702936556190252\n",
      "test_acc: 1.0\n",
      "Epoch 971, loss: 0.0056993719190359116\n",
      "test_acc: 1.0\n",
      "Epoch 972, loss: 0.005695817992091179\n",
      "test_acc: 1.0\n",
      "Epoch 973, loss: 0.005692268256098032\n",
      "test_acc: 1.0\n",
      "Epoch 974, loss: 0.00568872457370162\n",
      "test_acc: 1.0\n",
      "Epoch 975, loss: 0.0056851888075470924\n",
      "test_acc: 1.0\n",
      "Epoch 976, loss: 0.005681659560650587\n",
      "test_acc: 1.0\n",
      "Epoch 977, loss: 0.005678136833012104\n",
      "test_acc: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 978, loss: 0.005674620624631643\n",
      "test_acc: 1.0\n",
      "Epoch 979, loss: 0.005671108141541481\n",
      "test_acc: 1.0\n",
      "Epoch 980, loss: 0.005667606834322214\n",
      "test_acc: 1.0\n",
      "Epoch 981, loss: 0.005664107855409384\n",
      "test_acc: 1.0\n",
      "Epoch 982, loss: 0.005660617724061012\n",
      "test_acc: 1.0\n",
      "Epoch 983, loss: 0.005657134111970663\n",
      "test_acc: 1.0\n",
      "Epoch 984, loss: 0.0056536546908319\n",
      "test_acc: 1.0\n",
      "Epoch 985, loss: 0.0056501831859350204\n",
      "test_acc: 1.0\n",
      "Epoch 986, loss: 0.0056467182002961636\n",
      "test_acc: 1.0\n",
      "Epoch 987, loss: 0.005643258336931467\n",
      "test_acc: 1.0\n",
      "Epoch 988, loss: 0.005639804992824793\n",
      "test_acc: 1.0\n",
      "Epoch 989, loss: 0.005636363290250301\n",
      "test_acc: 1.0\n",
      "Epoch 990, loss: 0.005632919259369373\n",
      "test_acc: 1.0\n",
      "Epoch 991, loss: 0.005629485473036766\n",
      "test_acc: 1.0\n",
      "Epoch 992, loss: 0.005626059137284756\n",
      "test_acc: 1.0\n",
      "Epoch 993, loss: 0.0056226374581456184\n",
      "test_acc: 1.0\n",
      "Epoch 994, loss: 0.005619220435619354\n",
      "test_acc: 1.0\n",
      "Epoch 995, loss: 0.005615812726318836\n",
      "test_acc: 1.0\n",
      "Epoch 996, loss: 0.005612410604953766\n",
      "test_acc: 1.0\n",
      "Epoch 997, loss: 0.005609012208878994\n",
      "test_acc: 1.0\n",
      "Epoch 998, loss: 0.005605622660368681\n",
      "test_acc: 1.0\n",
      "Epoch 999, loss: 0.005602238699793816\n",
      "test_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch): #数据集级别迭代\n",
    "    for step, (x_train, y_train) in enumerate(train_db): #batch级别迭代\n",
    "        loss_all=0\n",
    "        with tf.GradientTape() as tape:# 记录梯度信息\n",
    "            x_train=tf.cast(x_train,dtype=tf.float32)\n",
    "            y_out=tf.matmul(x_train,w1) + b1 #计算神经网络的输出\n",
    "            y_poss=tf.nn.softmax(y_out)#化为概率分布\n",
    "            y_true=tf.one_hot(y_train,depth=3)#对真实值独热编码\n",
    "            loss=tf.reduce_mean(tf.square(y_poss-y_true))#计算loss\n",
    "            loss_all+=loss.numpy()\n",
    "            \n",
    "        grads = tape.gradient(loss, [w1,b1])\n",
    "        w1.assign_sub(lr * grads[0]) #参数自更新\n",
    "        \n",
    "        b1.assign_sub(lr * grads[1])\n",
    "    train_loss_result.append(loss_all/4)\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/4))\n",
    "    \n",
    "    total_correct=0\n",
    "    total_number=0\n",
    "    for x_test, y_test in test_db: \n",
    "        x_test=tf.cast(x_test,dtype=tf.float32)\n",
    "        y = tf.matmul(x_test, w1) + b1 # y为预测结果\n",
    "        y = tf.nn.softmax(y) # y符合概率分布\n",
    "        pred = tf.argmax(y, axis=1) # 返回y中最大值的索引，即预测的分类\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype) #调整数据类型与标签一致\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum (correct) # 将每个batch的correct数加起来\n",
    "        total_correct += int (correct) # 将所有batch中的correct数加起来\n",
    "        total_number += x_test.shape [0]\n",
    "        acc = total_correct / total_number\n",
    "        test_acc.append(acc)\n",
    "    print(\"test_acc:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.title('Acc Curve') # 图片标题\n",
    "plt.xlabel('Epoch') # x轴名称\n",
    "plt.ylabel('Acc') # y轴名称\n",
    "plt.plot(range(epoch+1),test_acc, label=\"$Accuracy$\") # 逐点画出test_acc值并连线\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.title('Loss Curve') # 图片标题\n",
    "plt.xlabel('Epoch') # x轴名称\n",
    "plt.ylabel('Loss') # y轴名称\n",
    "plt.plot(range(epoch+1),train_loss_result, label=\"$Loss$\") # 逐点画出test_acc值并连线\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py36",
   "language": "python",
   "name": "tf_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
